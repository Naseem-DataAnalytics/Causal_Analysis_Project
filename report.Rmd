---
title: "Causal Impact of a Sales Promotion"
author: "Naseem Mohammad"
date: "2025-09-09"
output: html_document
---

## Executive Summary

This project analyzed the causal impact of a simulated free shipping promotion, with an initial focus on data quality assurance. A segmentation analysis revealed the promotion's effect was highly variable across product categories: it drove a statistically significant **82.6% sales lift** for `health_beauty` but was ineffective for others. This lift for the `health_beauty` category alone is estimated to generate an additional **R\$69 in daily profit**. While the findings for high-performing categories are strong, a placebo test indicated that other seasonal factors may also be influencing sales, marking an area for future work.

```{r setup, include=FALSE}
# This chunk loads our toolboxes.
# install.packages("tidyverse")
# install.packages("lubridate")
# Now, we load the packages for this session.
library(tidyverse)
library(lubridate)
library(fixest)
```

```{r load-data, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk loads our first dataset
orders <- read_csv("data/olist_orders_dataset.csv")
# Load the customers dataset
customers <- read_csv("data/olist_customers_dataset.csv")
# Load the payments dataset
payments <- read_csv("data/olist_order_payments_dataset.csv")
# Load the additional files for segmentation
order_items <- read_csv("data/olist_order_items_dataset.csv")
products <- read_csv("data/olist_products_dataset.csv")
translation <- read_csv("data/product_category_name_translation.csv")
```

```{r join-data, echo=FALSE, warning=FALSE}
# This chunk creates a clean master table at the ORDER-ITEM level
# to avoid double-counting sales.
order_item_data <- orders %>%
  inner_join(customers, by = "customer_id") %>%
  inner_join(order_items, by = "order_id") %>%
  inner_join(products, by = "product_id") %>%
  inner_join(translation, by = "product_category_name") %>%
  # Create the correct revenue for each item
  mutate(item_revenue = price + freight_value)
```

```{r filter-data, echo=FALSE}
# This chunk filters our corrected data to keep only what we need
states_to_keep <- c("SP", "RJ", "MG")

analysis_data_filtered <- order_item_data %>%
  filter(order_status == "delivered") %>%
  filter(customer_state %in% states_to_keep)
```

```{r aggregate-data, echo=FALSE}
# This chunk creates our final analysis table by category
daily_sales_by_category <- analysis_data_filtered %>%
  mutate(date = as_date(order_purchase_timestamp)) %>%
  group_by(date, customer_state, product_category_name_english) %>%
  summarise(sales_revenue = sum(item_revenue), .groups = 'drop') # This line is now corrected

# Show the first 6 rows of the new table
head(daily_sales_by_category)

```

```{r plot-trends, echo=FALSE}
# This chunk creates our main project visualization
intervention_date <- as_date("2017-11-01")

# We now need to summarize our new category-level data to get the overall trend
plot_data <- daily_sales_by_category %>%
  group_by(date, customer_state) %>%
  summarise(total_daily_sales = sum(sales_revenue), .groups = 'drop')

ggplot(plot_data, aes(x = date, y = total_daily_sales, color = customer_state)) +
  geom_line(alpha = 0.8, linewidth = 1) + # Note: changed 'size' to 'linewidth' to avoid warnings
  geom_vline(xintercept = intervention_date, linetype = "dashed", color = "black") +
  labs(
    title = "Daily Sales Revenue: Treatment vs. Control",
    subtitle = "Visual check for the parallel trends assumption",
    x = "Date",
    y = "Total Daily Sales Revenue",
    color = "State"
  ) +
  theme_minimal()
```

```{r prep-segment-data, echo=FALSE}
# This chunk selects the top 10 categories and prepares data for the segmentation model

top_categories <- daily_sales_by_category %>%
  group_by(product_category_name_english) %>%
  summarise(total_sales = sum(sales_revenue)) %>%
  slice_max(order_by = total_sales, n = 10)

analysis_data_segmented <- daily_sales_by_category %>%
  filter(product_category_name_english %in% top_categories$product_category_name_english) %>%
  mutate(
    time = if_else(date >= intervention_date, 1, 0),
    treatment = if_else(customer_state == "SP", 1, 0),
    treatment_post = time * treatment
  )
```

```{r run-segment-model, echo=FALSE}
 # Final model attempt using standard R interaction syntax

# The term `treatment_post:product_category_name_english` estimates
# the promotion's effect for each category.
segmentation_model_final <- feols(log(sales_revenue) ~ treatment_post:product_category_name_english | customer_state + date + product_category_name_english,
                                  data = analysis_data_segmented)

# Show the results
summary(segmentation_model_final)
```

```{r prep-placebo-data, include=FALSE}
# --- Robustness Check: Placebo Test ---

# First, we must recreate the overall daily sales from our category-level data
overall_daily_sales <- daily_sales_by_category %>%
  group_by(date, customer_state) %>%
  summarise(total_sales = sum(sales_revenue), .groups = 'drop')

# Now, we can create the placebo data using this correct table
placebo_date <- as_date("2017-08-01")

placebo_data <- overall_daily_sales %>%
  mutate(
    time = if_else(date >= placebo_date, 1, 0),
    treatment = if_else(customer_state == "SP", 1, 0),
    treatment_post = time * treatment
  )

```

```{r run-placebo-model, include=FALSE}
# This chunk runs the placebo test model
placebo_model <- feols(log(total_sales) ~ treatment_post | customer_state + date, 
                       data = placebo_data)

# Show the results of the placebo test
summary(placebo_model)
```

### Robustness Check Results

We conducted a placebo test by moving the intervention date three months earlier to August 1st, 2017. The model found a statistically significant effect of 14.8% for this placebo date. This suggests that other time-varying factors may be influencing sales, and it serves as an important limitation to our main finding. Future work could explore more advanced time-series models to better account for these trends.

```{r tidy-results, echo=FALSE}
# This chunk tidies the model results for plotting
library(broom)

# Extract the coefficients from the CORRECT model object
segmented_results <- tidy(segmentation_model_final) %>%
  # Clean up the term names for better labels
  mutate(term = str_remove(term, "treatment_post:product_category_name_english")) %>%
  rename(category = term)

# View the new, clean table
segmented_results
```

```{r plot-segmentation, echo=FALSE}
# This chunk creates the final bar chart of segmented results

# We add a column to tell if the result is statistically significant
segmented_results_with_significance <- segmented_results %>%
  mutate(significant = if_else(p.value < 0.05, "Yes", "No"))

ggplot(segmented_results_with_significance, aes(x = fct_reorder(category, estimate), y = estimate, fill = significant)) +
  geom_col() +
  geom_errorbar(aes(ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error), width = 0.2) +
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = c("Yes" = "darkgreen", "No" = "grey50")) +
  labs(
    title = "Promotion Effect by Product Category",
    subtitle = "Estimated % increase in daily sales with 95% confidence intervals",
    x = "Product Category",
    y = "Estimated Effect on Sales"
  ) +
  theme_minimal()
```

```{r financial-impact, include=FALSE}
# --- Estimate Financial Impact ---

# 1. Isolate the 'health_beauty' category data in SP before the promotion
health_beauty_before <- analysis_data_segmented %>%
  filter(product_category_name_english == "health_beauty",
         time == 0,        # The 'before' period
         treatment == 1)   # In our treatment state (SP)

# 2. Calculate the average daily sales for this category before the promotion
avg_daily_sales_before <- mean(health_beauty_before$sales_revenue, na.rm = TRUE)

# 3. Get our estimated effect for this category from the model results
effect_health_beauty <- segmented_results %>%
  filter(category == "health_beauty") %>%
  pull(estimate) # pull() extracts a single value from a table

# 4. Calculate the estimated lift in daily revenue
estimated_revenue_lift_per_day <- avg_daily_sales_before * effect_health_beauty

# Print the result
estimated_revenue_lift_per_day

# 5. Assume a 20% profit margin and calculate the profit lift
profit_margin <- 0.20
estimated_profit_lift_per_day <- estimated_revenue_lift_per_day * profit_margin

# Print the final profit estimate
estimated_profit_lift_per_day
```

## Conclusion

After correcting for a data quality issue that was inflating sales figures, this analysis provides a more accurate and nuanced view of the promotion's impact. The key insight is the importance of segmentation. The promotion's massive success in high-performing categories (e.g., +82.6% for `health_beauty`) suggests a targeted marketing strategy would yield a much higher ROI than a site-wide campaign. Our financial estimate of over R\$69 in additional daily profit from this single category alone strongly supports this. The failed placebo test serves as a reminder that this model is an estimate, and further analysis into the data's underlying seasonality is recommended to refine these findings.

---

## Strategic Recommendations & Next Steps

The key takeaways from this analysis are:

* **What Happened**: Our free shipping promotion successfully increased sales, but the effect was highly concentrated in specific product categories.

* **So What?**: Blanket promotions are inefficient. We can achieve a much higher return on investment (ROI) by focusing our marketing efforts. Based on our model, the promotion in the `health_beauty` category alone generated an estimated **R$69 in extra profit per day**.

* **What's Next?**:
    1.  **Recommendation**: Pilot a new, targeted promotion for only the top-performing categories (like `health_beauty` and `bed_bath_table`).
    2.  **Future Analysis**: Explore *why* the promotion was so effective for these categories. Do they share common features, like higher profit margins or different customer behaviors (e.g., more repeat purchases)?
    3.  **Confirm with an Experiment**: To be 100% certain, the ideal next step would be to design and run a formal A/B test to confirm these findings before a full-scale rollout.
